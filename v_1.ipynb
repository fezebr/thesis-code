{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7fa4_kTprKa",
        "outputId": "ab6908e2-e82e-43a9-c1c6-80165f99d6f4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import itertools\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "import random\n",
        "import sklearn.preprocessing\n",
        "import sklearn.pipeline\n",
        "import torch\n",
        "import random\n",
        "import warnings\n",
        "import copy\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "standard = StandardScaler()\n",
        "minmax = MinMaxScaler()\n",
        "\n",
        " \n",
        "import json\n",
        "from IOHMM import UnSupervisedIOHMM\n",
        "from IOHMM import OLS, CrossEntropyMNL\n",
        "from hmmlearn import _hmmc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o0ohNGEp1fx"
      },
      "outputs": [],
      "source": [
        "# src = '/content/drive/MyDrive/Seminar/seminar-10'\n",
        "src = '/content/drive/MyDrive/seminar-10'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltODKyg8p295"
      },
      "outputs": [],
      "source": [
        "dataset = f\"{src}/train_FD001.txt\"\n",
        "\n",
        "\n",
        "df_full = pd.read_csv( dataset, sep=\" \", header=None, skipinitialspace=True).dropna(axis=1)\n",
        "df_full = df_full.rename(columns={0: 'unit', 1: 'cycle', 2: 'W1', 3: 'W2', 4: 'W3'})\n",
        "# Filter df_full for engine units 1 to 5\n",
        "df_full = df_full[df_full['unit'].isin(range(1,16))].reset_index(drop=True)\n",
        "\n",
        "df = df_full\n",
        "df_full.columns = df_full.columns.astype(str)\n",
        "\n",
        "df_A = df[df.columns[[0, 1]]] # unit and cycle\n",
        "df_W = df[df.columns[[2, 3, 4]]] # W1 w2 w3 (opration conditions)\n",
        "df_S = df[df.columns[list(range(5, 26))]] #sensors\n",
        "df_X = pd.concat([df_W, df_S], axis=1)\n",
        "\n",
        "df[['W1', 'W2', 'W3', *map(str, range(5, 26))]] = minmax.fit_transform(pd.concat([df_W, df_S], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRTSY52np8oy"
      },
      "outputs": [],
      "source": [
        "\n",
        "cols_to_drop = df.nunique()[df.nunique() == 1].index\n",
        "df = df.drop(cols_to_drop, axis=1)\n",
        "\n",
        "cols_to_drop = df.nunique()[df.nunique() == 2].index\n",
        "df = df.drop(cols_to_drop, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_mup8vyp-DA"
      },
      "outputs": [],
      "source": [
        "\n",
        "outputs = [col for col in df.columns if col.isdigit()]\n",
        "\n",
        "df_obs = PCA(n_components=len(outputs)).fit_transform(df[np.array(outputs).squeeze()])\n",
        "df_obs = pd.DataFrame(df_obs)\n",
        "df_input = PCA(n_components=1).fit_transform(df[['W1', 'W2']])\n",
        "df_hmm = df_obs\n",
        "df_hmm['W'] = df_input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0-7vPwHp_7c",
        "outputId": "6cc6a1cf-266a-43e5-cbe6-f347c56c5f02"
      },
      "outputs": [],
      "source": [
        "outputs = [[m] for m in df_obs.head() if type(m) == int]\n",
        "\n",
        "\n",
        "def split_X_lengths(X, lengths):\n",
        "    if lengths is None:\n",
        "        return [X]\n",
        "    else:\n",
        "        cs = np.cumsum(lengths)\n",
        "        n_samples = len(X)\n",
        "        if cs[-1] > n_samples:\n",
        "            raise ValueError(\"more than {} samples in lengths array {}\"\n",
        "                             .format(n_samples, lengths))\n",
        "        elif cs[-1] != n_samples:\n",
        "            warnings.warn(\n",
        "                \"less that {} samples in lengths array {}; support for \"\n",
        "                \"silently dropping samples is deprecated and will be removed\"\n",
        "                    .format(n_samples, lengths),\n",
        "                DeprecationWarning, stacklevel=3)\n",
        "        return np.split(X, cs)[:-1]\n",
        "\n",
        "# # Initialize IOHMM with two states\n",
        "np.Infinity = np.inf\n",
        "\n",
        "#\n",
        "num_states = 10\n",
        "SHMM = UnSupervisedIOHMM(num_states=num_states ,max_EM_iter=30, EM_tol=1e-3 )\n",
        "SHMM.set_models(model_emissions=[OLS(est_stderr=True), OLS(est_stderr=True), OLS(est_stderr=True), OLS(est_stderr=True),\n",
        "                                 OLS(est_stderr=True), OLS(est_stderr=True), OLS(est_stderr=True), OLS(est_stderr=True),\n",
        "                                 OLS(est_stderr=True), OLS(est_stderr=True), OLS(est_stderr=True), OLS(est_stderr=True),\n",
        "                                 OLS(est_stderr=True), OLS(est_stderr=True)],\n",
        "                model_transition=CrossEntropyMNL(solver='lbfgs'),\n",
        "                model_initial=CrossEntropyMNL(solver='lbfgs'))\n",
        "\n",
        "# We set operating conditions as the input covariate associate with the sensor output\n",
        "SHMM.set_inputs(covariates_initial=[], covariates_transition=['W'],\n",
        "                covariates_emissions=[['W']] * len(outputs))\n",
        "\n",
        "#we use sensor data as outputs\n",
        "SHMM.set_outputs(outputs)\n",
        "\n",
        "# lengths = [192, 174, 256, 203, ...] per engine\n",
        "lengths = [df_A[df_A['unit'] == i].cycle.max() for i in range(1, df_A['unit'].max() + 1)]\n",
        "split_data = split_X_lengths(df_hmm, lengths)\n",
        "SHMM.set_data(split_data)\n",
        "\n",
        "SHMM.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyBxuCm0qBsN",
        "outputId": "7f629257-9da9-4491-c821-e9dec570d25f"
      },
      "outputs": [],
      "source": [
        "\n",
        "#  viterbi\n",
        "log_gammas = SHMM.log_gammas  # A list of arrays, one for each sequence\n",
        "\n",
        "# Convert log probabilities to normal probabilities and find the most likely states\n",
        "state_sequences = [np.argmax(np.exp(sequence), axis=1) for sequence in log_gammas]\n",
        " \n",
        "for i, seq in enumerate(state_sequences):\n",
        "    print(f\"Sequence {i+1}: {seq}\")\n",
        "\n",
        "\n",
        "state_sequences = []\n",
        "log_gammas = SHMM.log_gammas\n",
        "for i in range(len(SHMM.log_gammas)): # i => for loop on each engine unit\n",
        "    for j in range(lengths[i]): # j => for loop on each timestep\n",
        "        state_sequences.append(np.argmax(np.exp(log_gammas[i])[j]))\n",
        "\n",
        "pred = [state_sequences[df[df['unit'] == i].index[0]:df[df['unit'] == i].index[-1] + 1] for i in\n",
        "        range(1, len(SHMM.log_gammas) + 1)]\n",
        "\n",
        "\n",
        "failure_states = [pred[i][-1] for i in range(len(SHMM.log_gammas) )]\n",
        "failure_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY1Bivwtv47E",
        "outputId": "63385caf-429e-48ca-b8d8-80ae49c9664d"
      },
      "outputs": [],
      "source": [
        "hierarchical = []\n",
        "h = []\n",
        "failure = np.unique(failure_states)\n",
        "failure\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(pred)):\n",
        "    h = []\n",
        "    for j in range(len(failure)):\n",
        "        h.append(np.where(np.array(pred[i]) == failure[j]))\n",
        "    h = np.squeeze(np.sort(np.concatenate(h, 1)))\n",
        "    hierarchical.append(h)\n",
        "\n",
        "\n",
        "\n",
        "for i, seq in enumerate(hierarchical):\n",
        "    print(f\"Sequence {i+1}: {seq}\")\n",
        "    print(f\"---------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8saW9hH9vh-b"
      },
      "source": [
        "<hr/>\n",
        "RL\n",
        "<hr/>\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
